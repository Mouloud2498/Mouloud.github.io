# üê≥üì¶ Analyse Big Data avec Docker & Hadoop (MapReduce Streaming)

## 1) Contexte
Dans un contexte e-commerce, les donn√©es de ventes peuvent devenir volumineuses.  
L‚Äôobjectif de ce projet est de montrer comment traiter un **gros fichier CSV** avec un pipeline **Hadoop MapReduce** ex√©cut√© dans **Docker**, en utilisant **Hadoop Streaming** (mappers/reducers Python).

üéØ **Objectif** : produire des indicateurs fiables et reproductibles √† partir d‚Äôun dataset de ventes :  
- **CA net par pays et par mois**
- **Top 10 produits** (par CA net)
- **Taux de retour**
- **R√©partition des paiements**

---

## 2) Probl√®me √† r√©soudre (Business Problem)
On dispose d‚Äôun flux de transactions contenant :
- pays, date, produit, quantit√©, prix
- mode de paiement
- statut de commande (retour / remboursement / livraison)

‚úÖ On veut r√©pondre √† des questions m√©tier :
1. Quel est le **CA net** (en tenant compte des retours) par **pays** et **mois** ?
2. Quels sont les **10 produits** les plus performants ?
3. Quel est le **taux de retour** global ?
4. Quels sont les **modes de paiement** les plus utilis√©s ?

---

## 3) Donn√©es
### G√©n√©ration des donn√©es
Le projet inclut un script qui g√©n√®re un fichier de ventes volumineux (CSV) pour simuler un contexte Big Data :

- `generate_sales_big.py` ‚Üí g√©n√®re `sales_big.csv` (objectif ~260 MB)

> Si tu utilises un fichier r√©el, indique-le ici.

### Sch√©ma de donn√©es (colonnes principales)
Exemples de colonnes utilis√©es :
- `country`, `date`, `product`, `quantity`, `price`
- `payment_method`
- `status` (ex: delivered / returned / refunded)

---

## 4) D√©marche (Processus)
### A) Pr√©paration
- G√©n√©ration du dataset volumineux (CSV)
- D√©marrage d‚Äôun environnement Hadoop via Docker (HDFS + YARN)

### B) Ingestion dans HDFS
- Cr√©ation d‚Äôun r√©pertoire HDFS
- Upload du fichier CSV dans HDFS

### C) Traitements MapReduce (Hadoop Streaming)
Chaque indicateur est calcul√© via un couple **mapper/reducer** Python :

1) **CA net par pays et par mois**
- Mapper : extrait la cl√© (pays, mois) et la valeur (montant, statut)
- Reducer : agr√®ge et calcule le CA net (en g√©rant retours/remboursements)

2) **Top 10 produits (CA net)**
- Mapper : (produit ‚Üí montant)
- Reducer : somme par produit puis tri pour conserver le top 10

3) **Taux de retour**
- Mapper : compte total commandes et retours
- Reducer : calcule % retour

4) **R√©partition des paiements**
- Mapper : (mode_paiement ‚Üí 1)
- Reducer : agr√®ge et calcule la distribution

### D) Export des r√©sultats
Les r√©sultats sont r√©cup√©r√©s depuis HDFS (ou affich√©s) dans des fichiers de sortie.

---

## 5) Hypoth√®ses (Assumptions)
- Le dataset suit un format CSV coh√©rent (s√©parateur, colonnes, types)
- Les statuts de commande sont corrects (ex: returned/refunded)
- Le CA net est calcul√© comme :  
  **CA net = ventes - retours/remboursements** (selon la r√®gle d√©finie)
- Les donn√©es sont suffisamment grandes pour justifier l‚Äôapproche MapReduce

---

## 6) KPI / Mesures d‚Äôimpact
Ce projet met en avant des KPI ‚Äúm√©tier‚Äù et ‚Äútechniques‚Äù :

### KPI m√©tier
- **CA net** par pays / mois
- **Top 10 produits** par CA net
- **Taux de retour (%)**
- **R√©partition des paiements (%)**

### KPI techniques (qualit√© & performance)
- Volume du dataset (ex : ~260MB)
- Temps d‚Äôex√©cution des jobs (si mesur√©)
- Reproductibilit√© (m√™mes r√©sultats avec les m√™mes donn√©es)

---

## 7) R√©sultats (exemples)
> Ajoute des captures dans `assets/` (recommand√©)

- `assets/hdfs_upload.png` (upload HDFS)
- `assets/job_run.png` (ex√©cution des jobs)
- `assets/output_sample.png` (extrait des r√©sultats)

Exemple d‚Äôaffichage :

![Upload HDFS](assets/hdfs_upload.png)
![Ex√©cution Job](assets/job_run.png)
![R√©sultats](assets/output_sample.png)

---


